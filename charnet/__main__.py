#!/usr/bin/env python3

"""Point entry of execution."""

import math

import os
import os.path

from enum import Enum, unique

import logging

import operator

import tempfile

import sys

import numpy as np

from scipy.stats import pearsonr
from scipy.optimize import curve_fit

from jinja2 import Environment, FileSystemLoader

import graph_tool as gt
import graph_tool.centrality as gt_central
import graph_tool.clustering as gt_cluster
import graph_tool.draw as gt_draw

sys.path.append('/usr/local/lib/python2.7/dist-packages/')

logging.basicConfig(level=logging.INFO)
LOGGER = logging.getLogger(__name__)

##########
# CONFIG #
##########
"""Properties for charnet project"""

# Directory containing Charnet data.
CHARNET_DATA_DIRECTORY = 'data/'

# Directory containing Stanford GraphBase data.
SGB_DATA_DIRECTORY = 'sgb_data/'

# System
DEFAULT_OUTPUT_DIRECTORY = tempfile.gettempdir()

# csv files
CSV_FIELDS_SEPARATOR = ','

# Graphs
GRAPH_EDGE_SYMBOL = '--'

class Project():
    """Project contains information about where to write the
    files generating during the calculation and plotting."""
    # Where to store files generated by the scripts.
    output_directory = DEFAULT_OUTPUT_DIRECTORY
    def __init__(self):
        return
    # Template for specific project configurations.
    def get_out_dir(self):
        """Return the directory to write the files."""
        return Project.output_directory
    def set_outdir(self, directory):
        """Set the directory to write the files."""
        Project.output_directory = directory


##########
# GRAPHS #
##########
# Main operations on graphs.

class Measure(Enum):
    """IDs of measures."""
    AVG_DEGREE_OF_NEIGHBORS = 0
    BETWEENNESS = 1
    CDF = 2
    CLOSENESS = 3
    CLUSTERING_COEFFICIENT = 4
    DEGREE = 5
    DEGREE_CENTRALITY = 6
    DENSITY = 7
    LOBBY = 8
    @staticmethod
    def get_label(measure_num):
        """Return the label of the measure ID."""
        label = {
            Measure.AVG_DEGREE_OF_NEIGHBORS: 'knn',
            Measure.BETWEENNESS: 'betweenness',
            Measure.CDF: 'Pk',
            Measure.CLOSENESS: 'closeness',
            Measure.CLUSTERING_COEFFICIENT: 'clustering coefficient',
            Measure.DEGREE: 'k',
            Measure.DEGREE_CENTRALITY: 'D',
            Measure.DENSITY: 'density',
            Measure.LOBBY: 'Lobby'
        }
        lab = label[measure_num]
        assert lab
        return lab

class Graphs():
    """Handle all graphs in one place."""
    centrality_nums = [
        Measure.BETWEENNESS,
        Measure.CLOSENESS,
        Measure.DEGREE_CENTRALITY
    ]

    def __init__(self):
        pass

    @staticmethod
    def create_graph():
        """Return the graph."""
        return gt.Graph(directed=False)
    @staticmethod
    def size(graph):
        '''Return the number of vertices in the graph G.'''
        assert graph
        return len(list(graph.vertices()))

    @staticmethod
    def length(graph):
        '''Return the number of edges in the graph G.'''
        assert graph
        return len(list(graph.edges()))

    @staticmethod
    def density(graph):
        '''The density of a network is the ratio of the number of links and
        the possible number of links
        '''
        assert graph
        n_verts = Graphs.size(graph)
        n_edges = Graphs.length(graph)
        return 2*float(n_edges) / (n_verts*(n_verts-1))

    @staticmethod
    def get_centrality_nums():
        """Return the ID of centralities."""
        return Graphs.centrality_nums

    @staticmethod
    def get_vprop_degrees(graph):
        """Return the properties of vertices and edges of the graph."""
        if graph.graph_properties["was_vprop_degree_set"] is False:
            graph.graph_properties["was_vprop_degree_set"] = True
            for vert in graph.vertices():
                graph.vertex_properties["degree"][vert] = vert.out_degree()
        return graph.vertex_properties["degree"]

    @staticmethod
    def degree_centrality(graph):
        '''Return an array of normalized degree centrality.'''
        vprop = Graphs.get_vprop_degrees(graph)
        n_verts = Graphs.size(graph)
        arr = [None] * n_verts
        for vert in graph.vertices(): # normalize
            arr[int(vert)] = float(vprop[vert]) / n_verts
        return arr

    @staticmethod
    def degree_stat(graph):
        '''Calculate the average degree and the standard deviation degree.
        '''
        deg_sum = [] # degree summation
        for vert in graph.vertices():
            deg_sum.append(vert.out_degree())
        return (np.mean(deg_sum), np.std(deg_sum))

    @staticmethod
    def get_centrality_values(graph, which):
        """Return the centrality values for the graph."""
        ewprops = graph.edge_properties["weight"]
        centr_func = None
        if which == Measure.BETWEENNESS:
            centr_func = \
                gt.PropertyMap.get_array(gt_central.betweenness(graph,
                                                                weight=ewprops,
                                                                norm=True)[0])
        elif which == Measure.CLOSENESS:
            centr_func = gt.PropertyMap.get_array(gt.centrality.closeness(graph, weight=ewprops))
        elif which == Measure.DEGREE_CENTRALITY:
            centr_func = Graphs.degree_centrality(graph)
        elif which == Measure.LOBBY:
            centr_func = lobby(graph)
        else:
            LOGGER.error('* Wrong centrality id=%s', which)
            exit()
        return centr_func

    @staticmethod
    def get_degree_avg_neighbors(graph):
        """Return the average degrees of vertices of the graph."""
        k2knns = {} # map degree to average neighbor degree average
        size = graph.num_vertices()
        # 2D arrray containing normalized float values
        # [:,0] is x and [:,1] is y
        vals = np.zeros((size, 2))
        for i, vert in enumerate(graph.vertices()):
            k = vert.out_degree()
            knn = 0.0 # degree average of neighbors
            for neighbor in vert.out_neighbors():
                knn += neighbor.out_degree()
            if vert.out_degree() > 0:
                knn /= vert.out_degree()
            else:
                continue
            # Append to 2D array in the form
            # | ... ... |
            # | k   knn |
            print(str(k), str(knn))
            vals[i, 0] = float(k)
            vals[i, 1] = knn
            if k not in k2knns:
                k2knns[k] = []
                k2knns[k].append(knn)
        # calculate the avg of knns
        knn_means = np.zeros((len(k2knns), 2))
        i = 0
        for k, knns in sorted(k2knns.items()):
            mean = np.mean(np.array(knns))
            knn_means[i, 0] = float(k)
            knn_means[i, 1] = mean
            i += 1
        # NORMALIZE DATA
        xmax = np.amax(np.array(vals[:, 0])) # column 0
        ymax = np.amax(np.array(vals[:, 1])) # column 1
        for i, _ in enumerate(vals[:, 0]):
            vals[i, 0] = vals[i, 0]/xmax
            vals[i, 1] = vals[i, 1]/ymax
        for i, _ in enumerate(knn_means[:, 0]):
            knn_means[:, 0][i] = knn_means[:, 0][i]/xmax
            knn_means[:, 1][i] = knn_means[:, 1][i]/ymax
        return (vals[:, 0], vals[:, 1], knn_means[:, 0], knn_means[:, 1])

#########
# BOOKS #
#########
# Books wraps the semantics of the Project.
# The books used are classified and some methods
# are implemented to allow data handling.

class SGB(Project):
    '''Handle specific configuration for books gathered by Stanford
       GraphBase project.'''
    def __init__(self):
        Project.__init__(self)
    def get_data_dir(self):
        """Directory containing data from Stanford GraphBase."""
        return 'sgb_data/'

class Charnet(Project):
    '''Handle specific configuration for books gathered by Charnet project.'''
    def __init__(self):
        Project.__init__(self)
    def get_data_dir(self):
        """Directory containing data."""
        return 'data/'

class BookGenre(Enum):
    '''Books are classified in categories.'''
    BIOGRAPHY = 0
    LEGENDARY = 1 # e.g., Bible
    FICTION = 2

class Book():
    """Superclass with methods to handle all data needed to obtain
        the measures for the networks of characters obtained from the chosen
        books."""
    def __init__(self):
        self.graph = Graphs.create_graph() # Graph to be created from the book
        self.avg = {} # Dictionary to load average values associated with a centrality as key
        self.was_read = False # if the data file was already parsed, dont do it again
        # Dictionaries to store graph information
        # map vertex index and its label
        self.graph.vertex_properties["label"] = self.graph.new_vertex_property("string")
        # map vertex 'index' object and its frequency
        self.graph.vertex_properties["frequency"] = self.graph.new_vertex_property("int")
        # map edge index and its weight
        self.graph.edge_properties["weight"] = self.graph.new_edge_property("int")
        # map vertex index and its character name
        self.graph.vertex_properties["char_name"] = self.graph.new_vertex_property("string")
        # map vertex label and its vertex 'index' object
        self.vprop_l2v = {}
        # Store a boolean value indicating if vertex PropertyMap containing degree
        # values was already filled
        self.graph.graph_properties["was_vprop_degree_set"] = \
            self.graph.new_graph_property("boolean")
        self.graph.graph_properties["was_vprop_degree_set"] = False
        # Store degree non-normalized degree of vertices
        self.graph.vertex_properties["degree"] = self.graph.new_vertex_property("int")
    def __str__(self):
        '''Return the name of the book.'''
        return 'Book'
    def set_graph_name(self, name):
        """Set the graph name for the current object."""
        self.graph.graph_properties["name"] = self.graph.new_graph_property("string")
        self.graph.graph_properties["name"] = name
    def get_char_label(self, idx):
        """Return the chracter label for the index idx."""
        return self.graph.vertex_properties["label"][idx]
    def set_char_label(self, idx, label):
        """Set a label for character with index idx."""
        self.graph.vertex_properties["label"][idx] = label
        self.vprop_l2v[label] = idx
    def set_char_name(self, idx, char_name):
        """Set a name for the character with index idx."""
        self.graph.vertex_properties["char_name"][idx] = char_name
    def get_char_idx_from_label(self, label):
        """Return the character index mapped to label."""
        return self.vprop_l2v[label]
    def add_char(self, label, char_name):
        '''Add character labelled with character name in the graph. Map label
        and frequency with index; and character name with label.'''
        vert = self.graph.add_vertex()
        idx = int(vert)
        self.set_char_label(idx, label)
        self.set_char_name(idx, char_name)
        self.graph.vertex_properties["frequency"][idx] = 0
    def inc_freq(self, label):
        """"Increment the frequency of character represented by label."""
        idx = self.get_char_idx_from_label(label)
        self.graph.vertex_properties["frequency"][idx] += 1

    def exists(self, label):
        '''Verify the existence of the label in the dictionary associated with
        the graph. The existence means the label was already inserted in the
        graph G.'''
        if label in self.vprop_l2v:
            return True
        return False
    def degree(self, label):
        """Return the degree of the character represented by label."""
        idx = self.get_char_idx_from_label(label)
        return self.graph.vertex(idx).out_degree()
    def met(self, char_lbl_a, char_lbl_b):
        '''Return True if character label a (char_lbl_a) have met with character
        label b (char_lbl_b), False otherwise.
        '''
        a_vert = self.get_char_idx_from_label(char_lbl_a)
        b_vert = self.get_char_idx_from_label(char_lbl_b)
        if self.graph.edge(a_vert, b_vert) is None:
            return False
        return True
    def add_encounter(self, char_lbl_a, char_lbl_b):
        """Add edge a-b."""
        a_vert = self.get_char_idx_from_label(char_lbl_a)
        b_vert = self.get_char_idx_from_label(char_lbl_b)
        edge = self.graph.add_edge(a_vert, b_vert)
        self.graph.edge_properties["weight"][edge] = 1
    def inc_weight(self, char_lbl_a, char_lbl_b):
        """Increment the weight of edge a-b."""
        a_vert = self.get_char_idx_from_label(char_lbl_a)
        b_vert = self.get_char_idx_from_label(char_lbl_b)
        edge = self.graph.edge(a_vert, b_vert)
        self.graph.edge_properties["weight"][edge] += 1
    def get_weight(self, char_lbl_a, char_lbl_b):
        """Return the weight of edge a-b."""
        a_vert = self.get_char_idx_from_label(char_lbl_a)
        b_vert = self.get_char_idx_from_label(char_lbl_b)
        edge = self.graph.edge(a_vert, b_vert)
        return self.graph.edge_properties["weight"][edge]
    def get_genre(self):
        """Return the genre."""
        return None
    def get_comment_token(self):
        '''Asterisk is used as comment to reflect same convention of SGB (Stanford GraphBase).'''
        return '*'
    def get_file_ext(self):
        '''Return the default file extension.'''
        return '.dat'
    def get_file_name(self):
        '''Return the file name to be read.'''
        return self.get_data_dir() + self.__str__() + self.get_file_ext()
    def get_graph(self):
        """Return the graph for the current book."""
        return self.graph
    def get_label(self):
        """Format the label of the book to print in table or plot."""
        return '\\emph{' + self.get_raw_book_label() + '}'
    def get_name(self):
        """Return the book name."""
        return self.__str__()
    def get_number_characters(self):
        """Return the number of characters."""
        assert self.graph
        return self.graph.num_vertices()
    def get_number_hapax_legomenas(self):
        """
        _Hapax_ _Legomena_ are words with occurrence frequency equals to one.
        """
        assert self.graph
        nr_hapaxes = 0
        for vert in self.graph.vertices():
            freq = self.graph.vertex_properties['frequency'][vert]
            if freq == 1:
                nr_hapaxes += 1
        return nr_hapaxes

    def get_number_dis_legomenas(self):
        """
        _Dis_ _Legomena_ are words with occurrence frequency equals to two.
        """
        assert self.graph
        nr_dis = 0
        for vert in self.graph.vertices():
            freq = self.graph.vertex_properties['frequency'][vert]
            if freq == 2:
                nr_dis += 1
        return nr_dis
    def get_raw_book_label(self):
        """Return the book label in uppercase."""
        return self.__str__().title()
    def get_vertex_color(self):
        '''Return the color set to vertices in the plot of graph. Default: white.'''
        return 'white'

    def read(self):
        """
        Read the file containing characters encounters of a book
        and return a graph.
        Returns
        -------
        a graph
        """
        are_edges = False
        book_name = self.get_name().title()
        # assert data file is not read several times
        if self.was_read is False:
            self.was_read = True
        else:
            return self.graph
        # set graph name
        self.set_graph_name(self.get_name())
        file_name = self.get_file_name()
        _file = open(file_name, "r")
        u_vert = 'AA' # store old vertex label and it is used to check it the order is right
        for line in _file:
            # ignore comments
            if line.startswith(self.get_comment_token()):
                continue
            # edges start after an empty line
            if line.startswith('\n') or line.startswith('\r'):
                are_edges = True
                continue
            # remove new line
            line = line.rstrip('\r\n')
            # boolean are_edges indicates if it is inside vertices region
            if are_edges is False:
                (v_vert, character_name) = line.split(' ', 1)
                # check the order
                if u_vert > v_vert:
                    LOGGER.error('* Labels %s and %s is \
                                 out of order in %s',
                                 u_vert, v_vert, book_name)
                    exit()
                #DEBUG
                LOGGER.debug("* G.add_vertice(%s, name=%s)", v_vert, character_name)
                #GUBED
                if not self.exists(v_vert):
                    self.add_char(v_vert, character_name)
                    u_vert = v_vert
                else:
                    LOGGER.error('* Label %s is repeated in book %s.', v_vert, book_name)
                    exit()
                continue
            # edges region from here
            # eg., split "1.2:ST,MR;ST,PH,MA;MA,DO" => ["1.2" , "ST,MR;ST,PH,MA;MA,DO"]
            (_, edges_list) = line.split(':', 1)
            # eg., split "ST,MR;ST,PH,MA;MA,DO" => ["ST,MR", "ST,PH,MA", "MA,DO"]
            edges = edges_list.split(';')
            if edges[0] == '': # eliminate chapters with no edges
                continue
            for edge in edges:
                # eg., split "ST,PH,MA" => ["ST", "PH", "MA"]
                verts = edge.split(',')  # vertices
                # add vertices to graph G if it does not exit
                # otherwise, increment frequency
                for v_vert in verts:
                    if not self.exists(v_vert):
                        LOGGER.error('* Label \"%s\" was not added \
                                     as node in the graph for book %s.',
                                     v_vert, book_name)
                        exit()
                    else:
                        self.inc_freq(v_vert)
                # add characters encounters (edges) to graph G
                for i, u_vert in enumerate(verts):
                    for j in range(i+1, len(verts)):
                        v_vert = verts[j]
                        # link u--v
                        if not self.met(u_vert, v_vert):
                            self.add_encounter(u_vert, v_vert)
                        else: # u--v already in G, increase weight
                            self.inc_weight(u_vert, v_vert)
                        #DEBUG
                        action = 'add'
                        w_vert = self.get_weight(u_vert, v_vert)
                        if w_vert > 1:
                            action = 'mod'
                        LOGGER.debug('* G.%s_edge(%s, %s, weight=%s)',
                                     action, u_vert, v_vert, w_vert)
                        #GUBED
        _file.close()
        LOGGER.info("* Read G from book \"%s\"", book_name)
        return self.graph

class Acts(Book, Charnet):
    """Data about Acts of Apostles gospel."""
    def __init__(self):
        Book.__init__(self)
        Charnet.__init__(self)
    def __str__(self):
        return 'acts'
    def get_genre(self):
        return BookGenre.LEGENDARY
    def get_vertex_color(self):
        """Return the color to fill the vertex."""
        return 'khaki'

class Apollonius(Book, Charnet):
    """Data about Applonius of Tyana book."""
    def __init__(self):
        Book.__init__(self)
        Charnet.__init__(self)
    def __str__(self):
        return 'apollonius'
    def get_genre(self):
        return BookGenre.LEGENDARY
    def get_vertex_color(self):
        """Return the color to fill the vertex."""
        return 'red'

class Arthur(Book, Charnet):
    """Data about king Arthur book."""
    def __init__(self):
        Book.__init__(self)
        Charnet.__init__(self)
    def __str__(self):
        return 'arthur'
    def get_genre(self):
        return BookGenre.FICTION
    def get_vertex_color(self):
        """Return the color to fill the vertex."""
        return 'cyan'

class David(Book, SGB):
    """Data about David Copperfield book."""
    def __init__(self):
        Book.__init__(self)
        SGB.__init__(self)
    def __str__(self):
        return 'david'
    def get_genre(self):
        return BookGenre.FICTION
    def get_vertex_color(self):
        """Return the color to fill the vertex."""
        return 'orange'

class Dick(Book, Charnet):
    """Data about Dick's biography."""
    def __init__(self):
        Book.__init__(self)
        Charnet.__init__(self)
    def __str__(self):
        return 'dick'
    def get_genre(self):
        return BookGenre.BIOGRAPHY
    def get_vertex_color(self):
        """Return the color to fill the vertex."""
        return 'orchid'

class Hawking(Book, Charnet):
    """Data about Hawking's biography."""
    def __init__(self):
        Book.__init__(self)
        Charnet.__init__(self)
    def __str__(self):
        return 'hawking'
    def get_genre(self):
        return BookGenre.BIOGRAPHY
    def get_vertex_color(self):
        """Return the color to fill the vertex."""
        return 'silver'

class Hobbit(Book, Charnet):
    """Data about Hobbit book."""
    def __init__(self):
        Book.__init__(self)
        Charnet.__init__(self)
    def __str__(self):
        return 'hobbit'
    def get_genre(self):
        return BookGenre.FICTION
    def get_vertex_color(self):
        """Return the color to fill the vertex."""
        return 'gold'

class Huck(Book, SGB):
    """Data about Huckleberry Finn book."""
    def __init__(self):
        Book.__init__(self)
        SGB.__init__(self)
    def __str__(self):
        return 'huck'
    def get_genre(self):
        return BookGenre.FICTION
    def get_vertex_color(self):
        """Return the color to fill the vertex."""
        return 'salmon'

class Luke(Book, Charnet):
    """Data about Luke gospel."""
    def __init__(self):
        Book.__init__(self)
        Charnet.__init__(self)
    def __str__(self):
        return 'luke'
    def get_genre(self):
        return BookGenre.LEGENDARY
    def get_vertex_color(self):
        """Return the color to fill the vertex."""
        return 'wheat'

class Newton(Book, Charnet):
    """Data about Newton's biography."""
    def __init__(self):
        Book.__init__(self)
        Charnet.__init__(self)
    def __str__(self):
        return 'newton'
    def get_genre(self):
        return BookGenre.BIOGRAPHY
    def get_vertex_color(self):
        """Return the color to fill the vertex."""
        return 'tan'

class Pythagoras(Book, Charnet):
    """Data about Pythagoras' biography"""
    def __init__(self):
        Book.__init__(self)
        Charnet.__init__(self)
    def __str__(self):
        return 'pythagoras'
    def get_genre(self):
        return BookGenre.LEGENDARY
    def get_vertex_color(self):
        """Return the color to fill the vertex."""
        return 'tomato'

class Tolkien(Book, Charnet):
    """Data about Tolkien's biography."""
    def __init__(self):
        Book.__init__(self)
        Charnet.__init__(self)
    def __str__(self):
        return 'tolkien'
    def get_genre(self):
        return BookGenre.BIOGRAPHY
    def get_vertex_color(self):
        """Return the color to fill the vertex."""
        return 'yellowgreen'

class Books(Book):
    """Books class joins in place books data."""
    was_already_read = False
    books = [             # row, col
        Dick(),       #  0,  0
        Apollonius(), #  1,  1
        Hobbit(),     #  2,  2
        Tolkien(),    #  3,  0
        Acts(),       #  0,  1
        David(),      #  1,  2
        Newton(),     #  2,  0
        Pythagoras(), #  3,  1
        Arthur(),     #  0,  2
        Hawking(),    #  1,  0
        Luke(),       #  2,  1
        Huck(),       #  3,  2
    ]
    genre_names = ['Biography', 'Legendary', 'Fiction']

    @staticmethod
    def get_genre_label(book):
        """Given a genre ID, return its letter label."""
        lab = None
        gen = book.get_genre()
        if gen == BookGenre.BIOGRAPHY:
            lab = 'B'
        elif gen == BookGenre.LEGENDARY:
            lab = 'L'
        elif gen == BookGenre.FICTION:
            lab = 'F'
        else:
            LOGGER.error('* Unknown book: \"%s\"', book.get_name())
            exit()
        return lab

    @staticmethod
    def get_genre_name(idx):
        """Given a genre ID, return its name."""
        return Books.genre_names[idx]

    @staticmethod
    def get_genre_enums():
        """Get the genres IDs"""
        return np.arange(0, len(Books.genre_names))

    @staticmethod
    def get_books():
        """Return the books data."""
        if Books.was_already_read is False:
            Books.was_already_read = True
            LOGGER.info("\n\t#### PRE-PROCESSING ####")
            for book in Books.get_books():
                book.read()
        return Books.books

########
# PLOT #
########
# Define functions to plot graphics used in the paper.

SEP = '_'

@unique
class AXIS(Enum):
    """Enumerate axis coordinates to use in arrays containing
    coordinates preoperties."""
    X = 0
    Y = 1
    Z = 2

def dump_book_data(xmeasure_num, ymeasure_num, book_name,
                   extension, x_coords, y_coords, xxs=None, yys=None,
                   book_genre=None):
    '''Dump data to output file.'''
    assert len(x_coords) == len(y_coords)
    labels = [Measure.get_label(xmeasure_num), \
              Measure.get_label(ymeasure_num)]
    _xcoords = []
    _ycoords = []
    label = ''
    file_name = os.path.join(Project().get_out_dir(), \
                             labels[AXIS.X.value] + SEP + labels[AXIS.Y.value] \
                             + SEP + book_name + extension)
    _file = open(file_name, 'w')
    for i, _ in enumerate(x_coords):
        if math.isnan(x_coords[i]) or math.isnan(y_coords[i]):
            continue
        line = '\n'
        if xxs is not None and yys is not None:
            if i < len(xxs):
                line = '\t' + str(xxs[i]) + '\t' + str(yys[i]) + '\n'
        # sorry, but \lblfmt is defined in templates/settings.gp
        if xmeasure_num == Measure.DENSITY and ymeasure_num == Measure.CLUSTERING_COEFFICIENT:
            label = '"\\\\tiny ' + book_name + ' (' + book_genre + ')"\t'
        line = label + str(x_coords[i]) + '\t' + str(y_coords[i]) + line
        _file.write(line)
        _xcoords.append(x_coords[i])
        _ycoords.append(y_coords[i])
    _file.close()
    print('* Wrote ' + file_name)
    return _xcoords, _ycoords, file_name

class Coordinates():
    '''Wrap coordinates x, y, z (optional).'''
    def __init__(self, x, y, z=0.0):
        self.x_coord = x
        self.y_coord = y
        self.z_coord = z
    def get(self, axis):
        """Return the value of selected axis."""
        val = 0.0
        if axis == 'x':
            val = self.x_coord
        elif axis == 'y':
            val = self.y_coord
        elif axis == 'z':
            val = self.z_coord
        else:
            print('Unknown axis {}'.format(axis))
        return val
    def set(self, axis, val):
        """Set values for coordinates."""
        if axis == 'x':
            self.x_coord = val
        elif axis == 'y':
            self.y_coord = val
        elif axis == 'z':
            self.z_coord = val
        else:
            print('Unknown axis {}'.format(axis))
            exit()

class DataInfo():
    """Class to wrap main data."""
    def __init__(self, title, filename, rvalue=0.0,
                 pvalue=0.0, slope=0.0, intercept=0.0,
                 coords_xmin=None, yoffset=.1, xoffset=0.0,
                 alpha=0.0):
        self.title = title
        self.filename = filename
        self.rvalue = rvalue
        self.pvalue = pvalue
        self.slope = slope
        self.intercept = intercept
        self.coords_xmin = coords_xmin
        self.labelpt_xoffset = xoffset
        self.labelpt_yoffset = yoffset
        self.alpha = alpha

class PlotInfo():
    """Class to wrap information for plotting."""
    def __init__(self, title, xlabel, ylabel, datainfos=None):
        self.title = title
        self.xlabel = xlabel
        self.ylabel = ylabel
        if datainfos is None:
            self.datainfos = []

def linear_func(x_coord, slope, offset):
    """Function that represents a linear one."""
    return x_coord*slope + offset

def test_ceil(x_coords, y_coords, xmax, ymax):
    """Check superior bounds."""
    if np.max(x_coords) > xmax or np.max(y_coords) > ymax:
        print(np.max(x_coords), np.max(y_coords))
        exit(-1)

def run_command(cmd, filename):
    """Execute a command in the OS."""
    cmd = cmd + filename
    print('\n$ {}'.format(cmd))
    os.system(cmd)

# These values were obtained running Matlab scripts from
# http://tuvalu.santafe.edu/~aaronc/powerlaws/{plfit,plpva}.m
class Fits():
    """Class with functions to perform a curve fitting."""
    # label: [kmin, alpha, p-value]
    parms = {
        # bio
        'dick': [3, 2.71, .84],
        'tolkien': [6, 2.66, .79],
        'newton': [2, 2.95, .82],
        'hawking': [2, 2.54, .05],
        # legendary
        'apollonius': [2, 2.43, .28],
        'acts': [6, 3.41, .79],
        'pythagoras': [1, 2.93, .73],
        'luke': [3, 2.26, .00],
        # fiction
        'hobbit': [1, 1.5, .00],
        'david': [14, 3.49, .39],
        'arthur': [3, 2.3, .66],
        'huck': [8, 3.5, .01]
    }
    @staticmethod
    def check_label(label):
        """Verify if the label exists."""
        if label not in Fits.parms:
            print('Wrong book name {}'.format(label))
            exit()
    @staticmethod
    def kmin(name):
        """Return the point where the fitting begins."""
        Fits.check_label(name)
        return Fits.parms[name][0]
    @staticmethod
    def alpha(name):
        """Return alpha from fitting."""
        Fits.check_label(name)
        return Fits.parms[name][1]
    @staticmethod
    def pvalue(name):
        """Returns p-value from fitting."""
        Fits.check_label(name)
        return Fits.parms[name][2]
class Plot():
    """Class with static functions to plot graphics used in the paper."""
    # significance level for statistical tests
    P = 0.05
    # plot command prefix
    GP_CMD = 'gnuplot '
    CMDs = ['cd preprint && ' + GP_CMD, 'cd presentation && ' + GP_CMD]
    # plot figure extension
    EXT = '.tex'
    # gnuplot extension
    PLT_EXT = '.gp'
    # data file extension
    DATA_EXT = '.dat'
    # gnuplot common settings
    GP_SET_PATH = os.path.join('templates/', 'settings.gp')
    # Graphs
    GS = []
    #
    BOOKS = []

    def __init__(self):
        pass

    @staticmethod
    def init():
        """Initialize environment for plotting. Remove old files. """
        tmpdir = Project().get_out_dir()
        # Initialize graphs.
        Plot.BOOKS = Books.get_books()
        for book in Plot.BOOKS:
            graph = book.get_graph()
            Plot.GS.append(graph)
        cmd = 'rm -f ' + tmpdir + '/*.' + Plot.EXT\
               + ' ' + tmpdir + '/*.' + Plot.PLT_EXT\
               + ' ' + tmpdir + '/*.' + Plot.DATA_EXT
        print('* Cleaning {}\n$ {}'.format(tmpdir, cmd))
        os.system(cmd)
    @staticmethod
    def init_multiplot_template():
        '''Initialize multiplot template.'''
        templates_dir = os.path.join('templates')
        env = Environment(loader=FileSystemLoader(templates_dir))
        template = env.get_template('multiplot.gp.j2')
        return template
    @staticmethod
    def do_density_x_clustering_coeff():
        '''Generate plotting of Density and clustering coefficient comparison.'''
        templates_dir = os.path.join('templates')
        env = Environment(loader=FileSystemLoader(templates_dir))
        template = env.get_template('plot.gp.j2')
        # index 0 is x, index 1 is y
        xcoords = [] 
        ycoords = [] # xcoords, ycoords
        maxs = [0.225, 1.0] # xmax, ymax
        measure_ids = [Measure.DENSITY, Measure.CLUSTERING_COEFFICIENT]
        # xlabel, ylabel
        labels = [Measure.get_label(measure_ids[AXIS.X.value]), \
                  Measure.get_label(measure_ids[AXIS.Y.value])]
        # y offset for point labels
        doff = 0.4 # default offset
        # offsets for point labels
        offs = {
            # bio
            'dick': [0, doff],
            'tolkien': [0, doff],
            'newton': [0, doff],
            'hawking': [-doff/2, doff],
            # legendary
            'apollonius': [9*doff, 0],
            'acts': [0, doff],
            'pythagoras': [9*doff, 0],
            'luke': [2*doff, doff],
            # fiction
            'hobbit': [0, doff],
            'david': [0, doff],
            'arthur': [4*doff, -doff],
            'huck': [0, doff]
        }
        plot_info = PlotInfo(Measure.get_label(measure_ids[AXIS.X.value]) \
                             + SEP + 'cluster-coeff', \
                             labels[AXIS.X.value], labels[AXIS.Y.value])
        for i in range(len(Plot.BOOKS)):
            book = Plot.BOOKS[i]
            book_name = book.get_name()
            graph = Plot.GS[i]
            x_coord = Graphs.density(graph)
            y_coord = gt_cluster.global_clustering(graph)[0]
            xcoords.append(x_coord)
            ycoords.append(y_coord)
            _x_coords, _y_coords, file_name = \
                    dump_book_data(measure_ids[AXIS.X.value], measure_ids[AXIS.Y.value],
                                   book_name, Plot.DATA_EXT, [x_coord], [y_coord],
                                   book_genre=Books.get_genre_label(book))
            plot_info.datainfos.append(DataInfo(book.get_name(), file_name,
                                                xoffset=offs[book_name][0],
                                                yoffset=offs[book_name][1]))
        (r_val, p_val) = pearsonr(xcoords, ycoords)
        popt, _ = curve_fit(linear_func, xcoords, ycoords)
        test_ceil(xcoords, ycoords, \
                  maxs[AXIS.X.value], maxs[AXIS.Y.value])
        filename = os.path.join(Project().get_out_dir(), plot_info.title + Plot.PLT_EXT)
        with open(filename, 'w') as file_handle:
            file_handle.write(template.render(
                plot_measure='DxCC',
                filename=file_name,
                extension=Plot.EXT,
                PlotInfo=plot_info,
                xmax=maxs[AXIS.X.value],
                ymax=maxs[AXIS.Y.value],
                outdir=Project().get_out_dir(),
                rvalue=r_val,
                pvalue=p_val,
                slope=popt[0],
                intercept=popt[1],
            ))
        for cmd in Plot.CMDs:
            run_command(cmd, filename)
    @staticmethod
    def do_centralities(supp):
        '''Generate plotting of centralities comparisons.'''
        template = Plot.init_multiplot_template()
        xmax = 1.0
        ymax = 0.5
        supp.send(('begin_table', 'Centralities $p$-values.'))
        for num in Graphs.get_centrality_nums():
            label = Measure.get_label(num)
            lobby_str = Measure.get_label(Measure.LOBBY)
            plot_info = PlotInfo(label + SEP + lobby_str, label, lobby_str)
            supp.send(('begin_subtable', '0.3'))
            supp.send(('xlabel', label))
            supp.send(('ylabel', lobby_str))
            supp.send(('begin_data', ''))
            for i in range(len(Plot.BOOKS)):
                book = Plot.BOOKS[i]
                book_name = book.get_name()
                graph = Plot.GS[i]
                x_coords = np.array(Graphs.get_centrality_values(graph, num))
                y_coords = np.array(Graphs.get_centrality_values(graph, Measure.LOBBY))
                x_coords, y_coords, file_name = dump_book_data(num, Measure.LOBBY,
                                                               book.get_name(), Plot.DATA_EXT,
                                                               x_coords, y_coords)
                (r_val, p_val) = pearsonr(x_coords, y_coords)
                # send to write to suplementary material in formatting.py
                supp.send(('book_name', book_name))
                if p_val < 0.0099:
                    supp.send(('pvalue', '{:.2e}'.format(float(p_val))))
                else:
                    supp.send(('pvalue', '{:.2f}'.format(float(p_val))))
                popt, _ = curve_fit(linear_func, x_coords, y_coords)
                plot_info.datainfos.append(DataInfo(book_name, file_name,
                                                    r_val, p_val, popt[0],
                                                    popt[1]))
                test_ceil(x_coords, y_coords, xmax, ymax)
            supp.send(('end_data', ''))
            supp.send(('end_subtable', ''))
            filename = os.path.join(Project().get_out_dir(), plot_info.title + Plot.PLT_EXT)
            with open(filename, 'w') as file_handle:
                file_handle.write(template.render(
                    plot_measure='centralities',
                    measure_type=label.lower(),
                    significance_level=Plot.P,
                    extension=Plot.EXT,
                    PlotInfo=plot_info,
                    xmax=xmax,
                    ymax=ymax,
                    outdir=Project().get_out_dir(),
                    nrows=4,
                    ncols=3,
                ))
            for cmd in Plot.CMDs:
                run_command(cmd, filename)
        supp.send(('end_table', ''))
    @staticmethod
    def do_assortativity():
        '''Generate assortativity multiplot on books.'''
        template = Plot.init_multiplot_template()
        xmax = 1.0
        ymax = 1.0
        plot_info = PlotInfo('assortativity', 'k', 'k_{nn}')
        for i, book in enumerate(Plot.BOOKS):
            graph = Plot.GS[i]
            (x_coords, y_coords, xx_coords, y_avgs) = Graphs.get_degree_avg_neighbors(graph)
            x_coords, y_coords, file_name = \
                dump_book_data(Measure.DEGREE,
                               Measure.AVG_DEGREE_OF_NEIGHBORS,
                               book.get_name(),
                               Plot.DATA_EXT,
                               x_coords, y_coords,
                               xx_coords, y_avgs)
            plot_info.datainfos.append(DataInfo(book.get_name(), file_name))
            test_ceil(x_coords, y_coords, xmax, ymax)
        filename = os.path.join(Project().get_out_dir(), plot_info.title + Plot.PLT_EXT)
        with open(filename, 'w') as file_handle:
            file_handle.write(template.render(
                plot_measure='assortativity',
                extension=Plot.EXT,
                PlotInfo=plot_info,
                xmax=xmax,
                ymax=ymax,
                outdir=Project.get_out_dir,
                nrows=4,
                ncols=3,
            ))
        for cmd in Plot.CMDs:
            run_command(cmd, filename)
    @staticmethod
    def do_cdf_w_fit(supp):
        '''Do cumulative distribution probability with fitting multiplot on books.'''
        import scipy.special as sz
        template = Plot.init_multiplot_template()
        xmax = 1.0
        ymax = 1.0
        xlabel = 'x'
        ylabel = 'Pr(X\\\\geq x)'
        supp.send(('begin_table', 'Degree cumulative distribution'))
        supp.send(('begin_subtable', '0.4'))
        supp.send(('xlabel', '$' + xlabel + '$'))
        supp.send(('ylabel', '$' + ylabel.replace("\\\\", "\\") + '$'))
        supp.send(('begin_data', ''))
        plot_info = PlotInfo('cdf', xlabel, ylabel)
        for i in range(len(Plot.BOOKS)):
            datax = []
            book = Plot.BOOKS[i]
            book_name = book.get_name()
            # alpha
            alpha = Fits.alpha(book_name)
            # kmin
            xmin = Fits.kmin(book_name)
            # p-value
            pval = Fits.pvalue(book_name)
            graph = Plot.GS[i]
            # store degrees to run fitting algorithm
            file_name = os.path.join(Project().get_out_dir(),
                                     book_name + '-degrees' + Plot.DATA_EXT)
            _file = open(file_name, 'w')
            for vert in graph.vertices():
                k = vert.out_degree()
                if k <= 0:
                    continue
                _file.write(str(k) + '\n')
                datax.append(k)
                if k > xmax:
                    xmax = k
            print('* Wrote ' + file_name + ';\t')
            _file.close()
            # Empirical data
            len_data = len(datax)
            x_coords = np.unique(datax)
            vals, _ = np.histogram(datax, x_coords)
            vals = vals/len_data # nomalize frequncy in hist.
            # inverse CDF
            y_coords = 1 - np.insert(np.cumsum(vals), 0, 0.0) # add 0.0 at front
            # Theoretical line
            cfy = np.power(np.arange(xmin, x_coords[len(x_coords)-1]+1), -alpha)/(sz.zeta(alpha) - \
                                           np.sum(np.power(np.arange(1, xmin), -alpha)))
            # do and invert cumulative distribution
            cfy = 1 - np.insert(np.cumsum(cfy), 0, 0.0)
            # normalize
            cfy = cfy * y_coords[np.where(x_coords == xmin)[0][0]]
            # get the corresponding values for y in the x axis
            cfx = np.arange(xmin, x_coords[len(x_coords)-1] + 2)
            x_coords, y_coords, file_name = dump_book_data(Measure.DEGREE, Measure.CDF, book_name,
                                                           Plot.DATA_EXT, x_coords, y_coords,
                                                           xxs=cfx, yys=cfy)
            plot_info.datainfos.append(DataInfo(book_name,
                                                file_name,
                                                alpha=alpha,
                                                coords_xmin=Coordinates(cfx[0], cfy[0]),
                                                pvalue=pval))
            # send to write to suplementary material in formatting.py
            supp.send(('book_name', book_name))
            supp.send(('pvalue', str(pval)))
        supp.send(('end_data', ''))
        supp.send(('end_subtable', ''))
        supp.send(('end_table', ''))
        filename = os.path.join(Project().get_out_dir(), plot_info.title + Plot.PLT_EXT)
        with open(filename, 'w') as file_handle:
            file_handle.write(template.render(
                plot_measure='cdf',
                significance_level=Plot.P,
                extension=Plot.EXT,
                PlotInfo=plot_info,
                xmax=xmax,
                ymax=ymax,
                outdir=Project().get_out_dir(),
                nrows=4,
                ncols=3,
            ))
        for cmd in Plot.CMDs:
            run_command(cmd, filename)
    @staticmethod
    def do_plot():
        """All plot functions are called at this function.
            Use a coroutine from Formatting to send parsed
            values to output."""
        # Prepare to write supplemental material sending info to coroutine
        supp = Formatting.coro_write_suppl('suppl')
        next(supp)
        Plot.init()
        Plot.do_centralities(supp)
        Plot.do_assortativity()
        Plot.do_density_x_clustering_coeff()
        Plot.do_cdf_w_fit(supp)
        # send key to close supplementary file
        supp.send(('CLOSE_FILE', ''))

##############
# FORMATTING #
##############

# Format instructions to produce output in LaTeX.

class Formatting():
    """Main class to format output."""
    suppl_f = None # file to write supplementary material

    def __init__(self):
        pass

    @staticmethod
    def write_hapax_legomena_table():
        """"Hapax Legomena: write_hapax_legomena_table() function write the
            _Hapax_ frequency to be included in the paper using LaTeX
            syntax for tables.
         """
        n2h = {} # map book name to hapax
        n2b = {} # map book name to book object
        tbl = "" # store table content string
        # Sort books by hapax
        for book in Books.get_books():
            name = book.get_name()
            graph = book.get_graph()
            n2h[name] = float(book.get_number_hapax_legomenas()) / Graphs.size(graph)
            n2b[name] = book

        file_name = os.path.join(Project().get_out_dir(), 'legomenas.tex')
        _file = open(file_name, "w")

        for name in Books.get_genre_enums():
            tbl += '\t\\begin{minipage}{.3\\textwidth}\\centering\n'
            tbl += '\t\t\\caption*{' + Books.get_genre_name(name) +'}\\\\ \\smallskip\n'
            tbl += '\t\t\\begin{tabular}{@{}p{1.65cm}p{1cm}@{}}\\toprule\n'
            tbl += '\t\t\\bf book  & $\\mathbf{HL}$\\\\ \\colrule\n'
            n2h_lst = sorted(n2h.items(), key=operator.itemgetter(1), reverse=True)
            for bname, _ in n2h_lst:
                book = n2b[bname]
                enum = book.get_genre()
                if enum.value == name:
                    nr_hap = book.get_number_hapax_legomenas()
                    nr_chars = Graphs.size(book.get_graph())
                    tbl += '\t\t\t' + book.get_label() + ' & '
                    tbl += '{0:.2f}'.format(float(nr_hap)/nr_chars)
                    tbl += ' \\\\ \n'
            tbl += '\t\t\\botrule \\end{tabular}\n'
            tbl += '\t\\end{minipage}\n'

        _file.write(tbl)
        _file.close()
        print('* Wrote ' + file_name)

    @staticmethod
    def write_global_measures():
        """Global measures for each character network are written as a table and
            included in a LaTeX file named `global.tex` to be included in the
            manuscript.
        """
        file_name = os.path.join(Project().get_out_dir(), 'global.tex')

        _file = open(file_name, "w")

        _file.write('''
        {\\small \\begin{tabular}{@{}cccccccc@{}}\\toprule
        \\hfil \\bf genre \\hfil
        & \\bf \\hfil book \\hfil
        & \\hfil\\hphantom{00} $\\mathbf n$ \\hphantom{00}\\hfil
        & \\hfil $\\mathbf m$\\hfil
        & \\hfil\\hphantom{0} $\\mathbf\\langle k\\rangle$\\hphantom{0} \\hfil
        & \\hfil\\hphantom{0} $\\mathbf \\rho$ \\hphantom{0}\\hfil
        & \\hfil\\hphantom{0} $\\mathbf c$\\hphantom{0}\\hfil \\\\ \n''')

        for _id in Books.get_genre_enums():
            line = '\t\t\\colrule\\multirow{4}{*}{'+ Books.get_genre_name(_id)  + '}' + '\n'
            books = Books.get_books()
            for book in books:
                enum = book.get_genre()
                if enum.value == _id:
                    graph = book.get_graph()
                    clustering_coeff, _ = gt_cluster.global_clustering(graph)
                    density = Graphs.density(graph)
                    (deg_avg, deg_stdev) = Graphs.degree_stat(graph)
                    # OUTPUT
                    line += '\t\t\t&\\emph{' + book.get_label() + '} & '
                    line += str(len(list(graph.vertices()))) + ' & '
                    line += str(len(list(graph.edges()))) + ' & '
                    line += '{0:.2f}'.format(deg_avg) + '$\\pm$'
                    line += '{0:.2f}'.format(deg_stdev) + ' & '
                    line += '{0:.3f}'.format(density) + ' & '
                    line += '{0:.3f}'.format(clustering_coeff) + ' & '
                    line += "\\\\ \n"
            _file.write(line)
        _file.write("\t\t\\botrule\\end{tabular}}\n")

        _file.close()
        print('* Wrote ' + file_name)

    @staticmethod
    def write_vertices_degree():
        """Write the degree of the vertices of a graph to output."""
        suf = '-vertex-degree.csv'
        books = Books.get_books()
        for book in books:
            degs = {}
            char_names = {}
            graph = book.get_graph()
            for vert in graph.vertices():
                lab = graph.vertex_properties["label"][vert]
                degs[lab] = vert.out_degree()
                char_names[lab] = graph.vertex_properties["char_name"][vert]
            file_name = book.get_name() + suf
            file_name = os.path.join(Project.get_out_dir(), file_name)
            _file = open(file_name, 'w')
            # Sort by degree in reverse order
            labs = sorted(degs.items(), key=lambda x: x[1], reverse=True)
            for lab, deg in labs:
                _file.write(lab +  CSV_FIELDS_SEPARATOR + '\"'
                            + char_names[lab] + '\"'
                            +  CSV_FIELDS_SEPARATOR + str(deg) + '\n')
            _file.close()
            print('* Wrote ' + file_name)

    @staticmethod
    def write_vertices_frequency():
        """Write the frequency of vertices to output."""
        suf = '-vertex-frequency.csv'
        sep = ','
        books = Books.get_books()
        for book in books:
            freqs = {}
            char_names = {}
            graph = book.get_graph()
            file_name = book.get_name() + suf
            file_name = os.path.join(Project.get_out_dir(), file_name)
            _file = open(file_name, 'w')
            for vert in graph.vertices():
                lab = graph.vertex_properties["label"][vert]
                freqs[lab] = graph.vertex_properties["frequency"][vert]
                char_names[lab] = graph.vertex_properties["char_name"][vert]
            labs = sorted(freqs.items(), key=lambda x: x[1], reverse=True)
            for lab, freq in labs:
                _file.write(lab + sep + '\"' + char_names[lab] + '\"'+ sep + str(freq) + '\n')
            _file.close()
            print('* Wrote ' + file_name)

    @staticmethod
    def write_edges_weight():
        """Write the weight of edges to output."""
        suf = '-edge-weight.csv'
        for book in Books.get_books():
            weights = {}
            char_names = {}
            graph = book.get_graph()
            file_name = os.path.join(Project.get_out_dir(),
                                     book.get_name() + suf)
            _file = open(file_name, 'w')
            for edge in graph.edges():
                src = edge.source()
                dest = edge.target()
                lab = graph.vertex_properties["label"][src]
                lab += GRAPH_EDGE_SYMBOL + graph.vertex_properties["label"][dest]
                weights[lab] = graph.edge_properties["weight"][edge]
                char_names[lab] = '\"' + graph.vertex_properties["char_name"][src] + '\"' \
                                  +  GRAPH_EDGE_SYMBOL \
                                  + '\"' + graph.vertex_properties["char_name"][dest] + '\"'
            labs = sorted(weights.items(), key=lambda x: x[1], reverse=True)
            for lab, weight in labs:
                _file.write(lab + CSV_FIELDS_SEPARATOR + char_names[lab] \
                            +  CSV_FIELDS_SEPARATOR + str(weight) + '\n')
            _file.close()
            print('* Wrote ' + file_name)

    @staticmethod
    def coro_write_suppl(filename):
        """Write supplementary material like p-values to output.
        Here we use coroutines to receive values from parser."""
        xlbl = '' # x label
        ylbl = '' # y label
        file_name = os.path.join('preprint/', filename + '.tex')
        _file = open(file_name, 'w')
        _file.write('\\pagebreak\\section*{Supplementary Material}\n')
        while True:
            (key, content) = yield # receive the message as a tuple
            if key == 'begin_table':
                _file.write('\\begin{table}[ht]\n')
                _file.write('\t\\begin{center} \n')
                _file.write('\t\\tbl{' + content + ' $p$-values.}\n')
                _file.write('{') # OPEN BRACKET
            elif key == 'begin_subtable':
                _file.write('\\begin{minipage}{' + content + '\\textwidth}\n')
            elif key == 'xlabel':
                xlbl = content
            elif key == 'ylabel':
                ylbl = content
                _file.write('\\hspace{.7cm}\\hbox{' + xlbl + '$\\times$' + ylbl +
                            '} \\par \\smallskip\n')
            elif key == 'begin_data':
                _file.write('\t\\begin{tabular}{@{}p{1.6cm}p{1.3cm}@{}} \\toprule \n')
                _file.write('\t\t\\bf book & $\\mathbf p$ \\\\ \\colrule \n')
            elif key == 'book_name':
                _file.write('\t\t' + content + ' & ')
            elif key == 'pvalue':
                _file.write(content + ' \\\\ \n')
            elif key == 'end_subtable':
                _file.write('\\end{minipage}\n')
            elif key == 'end_data':
                _file.write('\t\\botrule\\end{tabular}')
            elif key == 'end_table':
                _file.write('\n}\n') # CLOSE BRACKET
                _file.write('\t\\end{center}\n')
                _file.write('\\end{table}\n')
            elif key == 'CLOSE_FILE':
                _file.close()
                print('* Wrote ' + file_name)
            else:
                print('\n******** ERROR: wrong key: '+ key +' ********')
                exit()


########
# DRAW #
########
# Draw class to draw graphs.

class Draw():
    """Draw graphs."""
    def __init__(self):
        return

    def __str__(self):
        return self.__class__.__name__

    @staticmethod
    def do_graphs():
        '''Graphs for the characters' encounters are drawn for visualization.'''
        LOGGER.info('* Drawing graphs...')
        for book in Books.get_books():
            graph = book.get_graph()
            color = book.get_vertex_color()
            vprop_degrees = Graphs.get_vprop_degrees(graph)
            file_name = 'g-' + book.get_name() + '.png'
            file_name = os.path.join(Project().get_out_dir(), file_name)
            pos = gt_draw.arf_layout(graph, max_iter=0)
            gt_draw.graph_draw(graph, pos=pos, output=file_name,
                               vertex_text_color="black",
                               vertex_font_size=12,
                               vertex_fill_color=color,
                               vertex_text=graph.vertex_properties["label"],
                               vertex_size=vprop_degrees,
                               edge_pen_width=graph.edge_properties["weight"])
            LOGGER.info('* Wrote %s', file_name)


#########
# LOBBY #
#########
# This module has the function to calculate Lobby centrality.

HANDLER = None
if LOGGER.getEffectiveLevel() == logging.DEBUG:
    HANDLER = logging.FileHandler(os.path.join(Project.get_out_dir(), 'lobby.log'))
    FORMATTER = logging.Formatter('%(message)s')
    HANDLER.setFormatter(FORMATTER)
    LOGGER.addHandler(HANDLER)

def lobby(graph):
    """ Lobby or h index
        ================

        All graph vertices are traversed and Lobby index is calculated
        and stored in the lobby macro-field.

        If a node has the following list of neighbors sorted by degree:

         ==========  ========
         neighbor     degree
         ==========  ========
         1          21
         2          18
         3           4
         4           3
         ==========  ========

         the Lobby index is 3 because degree $\\leq$ neighbor_position.

    """
    n_verts = len(list(graph.vertices()))
    lobbies = [0] * n_verts

    LOGGER.debug('* %s', graph.graph_properties["name"])

    for vert in graph.vertices():

        LOGGER.debug('%s\tdegree=%s',
                     graph.vertex_properties['label'][vert],
                     str(vert.out_degree()))

        degs = [] # neighbors' degree

        for neighbor in vert.out_neighbors():
            degs.append(neighbor.out_degree())

        degs.sort()
        degs.reverse()
        old_idx = idx = 0
        for deg in degs:
            lob = idx = idx + 1

            LOGGER.debug("\t%s\t%s", str(idx), str(deg))

            if deg < idx:
                lob = old_idx
                break
            old_idx = idx

            LOGGER.debug("** Lobby=%s", str(lob))

        lobbies[int(vert)] = float(lob) / n_verts # normalize by N vertices

        if HANDLER:
            LOGGER.debug('* Wrote %s', HANDLER.stream.name)

    return lobbies

########
# MAIN #
########

def run_all_tasks():
    """Run all tasks available."""
    i = 1
    while True:
        print(HEADERS[i])
        TASKS[i]()
        i += 1
        if i == len(TASKS)-1: # BUG: without this, in this way, dont stop
            exit()

# header to tasks dictionary
TASKS = [None, # sys.argv[0] name of the program, no flag associated
         Plot.do_plot, # -c
         Draw.do_graphs, # -g
         Formatting.write_global_measures, # -m
         Formatting.write_hapax_legomena_table, # -l
         Formatting.write_vertices_degree, # -d
         Formatting.write_vertices_frequency, # -f
         Formatting.write_edges_weight, # -e
         run_all_tasks] # -a

# headers
HEADERS = ["__main__",
           "\n\t#### TASK 1 - Plot graphics ####",
           "\n\t#### TASK 2 - Draw graph ####",
           "\n\t#### TASK 3 - Write global measures ####",
           "\n\t#### TASK 4 - Write the frequency of _hapax_ _legomena_ ####",
           "\n\t#### TASK 5 - Write the vertices' degree ####",
           "\n\t#### TASK 6 - Write the characters' frequency ####",
           "\n\t#### TASK 7 - Write the edges' weight ####",
           "\n\t#### RUNNING ALL TASKS ####"]

def usage():
    """Write how to use the program."""
    print('* Usage: python3 ' + sys.argv[0] + ''' [options]
    OPTIONS
    -p, --plot
    \tPlot the lobby and other centralities comparisons, assortativity mixing and degree distribution with fitting.
    -g, --draw-graph
    \tDraw the graph of characters encounters for visualization generating PNG files.
    -m, --global-measures
    \tWrite global measures in a table in a LaTeX file.
    -l, --legomena
    \tWrite the frequency of hapax legomena, characters that appear only once in a table in a LaTeX file.
    -d, --degree
    \tWrite the vertices' degree in a file named \"{dir}/<book_name>-vertex-degree.csv\".
    -f, --frequency
    \tWrite the frequency of characters' appearance in a file named \"{dir}/<book_name>-vertex-frequency.csv\".
    -e, --weight
    \tWrite the weight of edges in a file named \"{dir}/<book_name>-edge-weight.csv\".
    -a, --all
    \tExecute all options.
    -o <directory>, --output-dir <directory>
    \tSet the <directory> to write the generated files. Default directory: \"{dir}\"
    -h, --help
    \t Print this help message.
    One of the flags listed above must be selected, with exception of the \"-o\" or
    \"--output-dir\" that changes the program behavior and it is optional.
    '''.format(dir=Project().get_out_dir()))
    exit()
def print_out_banner(directory):
    """Print a header and write the directory where output will be send."""
    spc = '\n\n'
    line = '\t\t################################################'
    print(spc)
    print(line)
    print('\t\t  Writing output to \"' + directory + '\"')
    print(line)
    print(spc)

# The main subroutine declares some attributes associated with the
# books. Those attributes are used to label the books and to
# standardize the pictorial elements properties like color and point
# marker in the plot.
def main():
    # Boolean array to store state of the flags
    OPTS = [False] * len(TASKS)
    # numer og arguments
    LEN_ARGS = len(sys.argv)
    # retrieve the flags set by the user
    if LEN_ARGS > 1:
        arg_no = 1
        while arg_no < LEN_ARGS:
            opt = sys.argv[arg_no]
            # OPTIONAL
            if opt == "-o" or opt == "--output-dir":
                arg_no += 1
                if arg_no == LEN_ARGS:
                    usage()
                _dir = sys.argv[arg_no]
                _dir = _dir.rstrip('\n')
                if os.path.exists(_dir):
                    Project.set_outdir(_dir)
                else:
                    LOGGER.error(' Directory \"%s\" does not exists!', _dir)
                    exit()
            elif opt == "-p" or opt == "--plot":
                OPTS[1] = True
            elif opt == "-g" or opt == "--draw-graph":
                OPTS[2] = True
            elif opt == "-m" or opt == "--global-measures":
                OPTS[3] = True
            elif opt == "-l" or opt == "--legomena":
                OPTS[4] = True
            elif opt == "-d" or opt == "--degree":
                OPTS[5] = True
            elif opt == "-f" or opt == "--frequency":
                OPTS[6] = True
            elif opt == "-e" or opt == "--weight":
                OPTS[7] = True
            elif opt == "-a" or opt == "--all-tasks":
                OPTS[8] = True
                for arg_no in range(1, LEN_ARGS-1): # to not repeat tasks
                    OPTS[arg_no] = False
            elif opt == "-h" or opt == "--help": # help make exit
                usage()
            else:
                LOGGER.error('* Unknown OPTION: %s', opt)
                usage()
            arg_no += 1
    else:
        usage()

    for arg_no in range(1, len(OPTS)):
        if OPTS[arg_no] is True:
            LOGGER.info(HEADERS[arg_no])
            TASKS[arg_no]()


main()
